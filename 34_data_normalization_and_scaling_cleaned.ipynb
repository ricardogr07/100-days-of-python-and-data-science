{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaa261ff",
   "metadata": {},
   "source": [
    "# Day 34 — Data Normalization and Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27f70a5",
   "metadata": {},
   "source": [
    "In today’s post, we’ll focus on data normalization and scaling, two essential preprocessing techniques for machine learning. Whether you're building a predictive model or performing exploratory data analysis, normalization and scaling ensure that your features are on the same scale, improving model performance and reducing bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc27618",
   "metadata": {},
   "source": [
    "## Why Normalize and Scale Data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428c592c",
   "metadata": {},
   "source": [
    "Machine learning algorithms, especially distance-based models like K-Nearest Neighbors (KNN), linear models, and neural networks, perform better when input features have similar scales. Normalization and scaling help in:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debf4b25",
   "metadata": {},
   "source": [
    "- **Improving Model Performance:** Ensuring that all features are weighted equally in algorithms sensitive to feature magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af55cf5",
   "metadata": {},
   "source": [
    "- **Handling Skewed Data:** Dealing with extreme values that might affect model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ca3fca",
   "metadata": {},
   "source": [
    "- **Speeding Up Convergence:** In optimization algorithms, normalized features help models converge faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b918eb4d",
   "metadata": {},
   "source": [
    "## Normalization vs. Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f20a0c",
   "metadata": {},
   "source": [
    "- **Normalization** typically scales your data to a range of [0, 1] or [-1, 1], ensuring all features have similar magnitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03af0837",
   "metadata": {},
   "source": [
    "- **Scaling** standardizes features so they have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df45580",
   "metadata": {},
   "source": [
    "## Tutorial: Using Normalization Techniques in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bc1d76",
   "metadata": {},
   "source": [
    "We’ll explore how to apply normalization and scaling to a dataset using Pandas and Scikit-learn libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7915db1d",
   "metadata": {},
   "source": [
    "### Step 1: Importing the Necessary Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c7ae44",
   "metadata": {},
   "source": [
    "Make sure you have Pandas and Scikit-learn installed. If not, you can install them using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38375f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5a5286",
   "metadata": {},
   "source": [
    "Then, import the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95da70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3066a1fb",
   "metadata": {},
   "source": [
    "### Step 2: Loading a Sample Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39809e9a",
   "metadata": {},
   "source": [
    "Let’s use a sample dataset of customer data to demonstrate normalization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8347ee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset of customer attributes\n",
    "data = pd.DataFrame({\n",
    "    'Annual Income': [30000, 50000, 70000, 100000, 120000],\n",
    "    'Age': [22, 35, 45, 50, 60],\n",
    "    'Credit Score': [650, 720, 800, 680, 710]\n",
    "})\n",
    "\n",
    "# Displaying the dataset\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a859659c",
   "metadata": {},
   "source": [
    "### Step 3: Applying Min-Max Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba792d70",
   "metadata": {},
   "source": [
    "Min-Max Scaling transforms data into a range of [0, 1], which is ideal for algorithms that require normalized input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e790deee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(data)\n",
    "\n",
    "# Converting back to DataFrame for easy viewing\n",
    "normalized_df = pd.DataFrame(normalized_data, columns=['Annual Income', 'Age', 'Credit Score'])\n",
    "print(\"Normalized Data (Min-Max Scaling):\")\n",
    "print(normalized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbc8465",
   "metadata": {},
   "source": [
    "### Step 4: Applying Standard Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fa5882",
   "metadata": {},
   "source": [
    "Standard Scaling ensures that the features have a mean of 0 and a standard deviation of 1. It’s useful for algorithms that assume normality in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf03977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Standard Scaling (Z-Score Normalization)\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Converting back to DataFrame for easy viewing\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=['Annual Income', 'Age', 'Credit Score'])\n",
    "print(\"Scaled Data (Standard Scaling):\")\n",
    "print(scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5357dc40",
   "metadata": {},
   "source": [
    "## Use Case: Preprocessing Data for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b542dd3f",
   "metadata": {},
   "source": [
    "Let’s look at how data normalization and scaling can help improve machine learning model performance. Imagine you’re building a K-Nearest Neighbors (KNN) model, which is sensitive to feature magnitudes. Before feeding the data into the model, we need to normalize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6643de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sample classification dataset with a target variable\n",
    "data['Target'] = [1, 0, 1, 0, 1]\n",
    "\n",
    "# Splitting the dataset into training and test sets\n",
    "X = data.drop('Target', axis=1)\n",
    "y = data['Target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalizing the training data using Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Applying KNN with normalized data\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "score = knn.score(X_test_scaled, y_test)\n",
    "\n",
    "print(f\"KNN Accuracy with Normalized Data: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae581622",
   "metadata": {},
   "source": [
    "### Explanation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6df8a0",
   "metadata": {},
   "source": [
    "In this use case, we used Min-Max Scaling to normalize the dataset before applying a KNN model, improving its performance by ensuring that all features contribute equally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2095f9",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570eccde",
   "metadata": {},
   "source": [
    "In today’s post, we explored data normalization and scaling, key preprocessing steps for machine learning. These techniques help ensure that models perform optimally by bringing features to a common scale, reducing bias from feature magnitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d8f3b6",
   "metadata": {},
   "source": [
    "### Key Takeaways:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a07c5d",
   "metadata": {},
   "source": [
    "- Normalization is crucial for models that require bounded inputs, like neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582965c8",
   "metadata": {},
   "source": [
    "- Scaling (Z-score normalization) is helpful when data must follow a normal distribution, improving performance for models like linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315c682f",
   "metadata": {},
   "source": [
    "- Preprocessing your data before training your machine learning models is a critical step to improve model accuracy and convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e94818d",
   "metadata": {},
   "source": [
    "Stay tuned for tomorrow’s post, where we’ll dive into advanced feature engineering!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
